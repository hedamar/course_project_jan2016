<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Course Project January 2016 : ">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Course Project January 2016</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/hedamar/course_project_jan2016">View on GitHub</a>

          <h1 id="project_title">Course Project January 2016</h1>
          <h2 id="project_tagline"></h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/hedamar/course_project_jan2016/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/hedamar/course_project_jan2016/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <p>&lt;!DOCTYPE html&gt;</p>

<p></p>

<p></p>

<p>

</p>

<p></p>



<p>
</p>







code{white-space: pre;}

<p></p>




  pre:not([class]) {
    background-color: white;
  }




<p></p>

<p></p>


.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img { 
  max-width:100%; 
  height: auto; 
}


<div>




<div id="project-for-machine-learning-class.">
<h1>
<a id="project-for-machine-learning-class" class="anchor" href="#project-for-machine-learning-class" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Project for Machine Learning Class.</h1>
<div id="load-libraries-and-the-data.-then-choose-the-variables-to-be-used-in-the-prediction">
<h2>
<a id="load-libraries-and-the-data-then-choose-the-variables-to-be-used-in-the-prediction" class="anchor" href="#load-libraries-and-the-data-then-choose-the-variables-to-be-used-in-the-prediction" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Load libraries and the data. Then, choose the variables to be used in the prediction</h2>
<pre><code>library(caret)
library(gbm)

cp_training_data_raw &lt;- read.csv("pml-training.csv", header = TRUE, sep = ",", quote = "\"", dec = ".", fill = TRUE, comment.char = "")
cp_testing_data_raw &lt;- read.csv("pml-testing.csv", header = TRUE, sep = ",", quote = "\"", dec = ".", fill = TRUE, comment.char = "")</code></pre>
<p>Visual inspection of the testing data (not shown here for brevity) reveals that a number of potential predictors are all “NA”s in the test data. These variables are also entirely (or almost entirely) missing from the training data. Therefore, I decided to remove these variables as potential predictors while training the model. In addition, I decided to remove the mutliple time stamp-related variables and the counter X from the set of predictors.</p>
<pre><code>cp_testing_data &lt;- cp_testing_data_raw[, colSums(is.na(cp_testing_data_raw)) != nrow(cp_testing_data_raw)]
cp_testing_drop &lt;- cp_testing_data_raw[, colSums(is.na(cp_testing_data_raw)) == nrow(cp_testing_data_raw)]
variables_drop &lt;- names(cp_testing_drop)

cp_training_data &lt;- cp_training_data_raw[ , -which(names(cp_training_data_raw) %in% variables_drop)]

cp_training_data &lt;- cp_training_data[ , -which(names(cp_training_data) %in% c("X", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp"))]</code></pre>
<p>All remaining variables are used as predictors in the model.</p>
</div>

<div id="model-choice-and-choice-of-cross-validation-metholodgy">
<h2>
<a id="model-choice-and-choice-of-cross-validation-metholodgy" class="anchor" href="#model-choice-and-choice-of-cross-validation-metholodgy" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Model Choice and Choice of Cross-Validation Metholodgy</h2>
<p>I decided to use a random forest model, since it is highly accurate. As discussed in class, the main concerns with random forests are (a) speed, (b) interpretability and (c) overfitting. Interpretability is not an issue for this assignment, since we are not asked to interpret the results anyway. I took some steps to improve the speed (discussed below). Overfitting remains an issue, but overall, the model performed well on the test set, so I didn’t see a point in going back and trying another model.</p>
<p>Regarding cross-validation, I decided to do K-fold cross-validation, where k = 10. This choice of K-fold CV was mostly driven by speed/computational power issues. The default CV for random forest in caret is repeated bootstrapping, which results in the model needing a lot of time to run. Finally, I set k = 10, since 3 or 5 seemed too low and a number of sources, including the Wikipedia page for K-fold cross-validation (<a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation">https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation</a>), state that k = 10 is very commonly used.</p>
</div>

<div id="running-the-model-reporting-the-accuracy-and-the-expected-out-of-sample-error">
<h2>
<a id="running-the-model-reporting-the-accuracy-and-the-expected-out-of-sample-error" class="anchor" href="#running-the-model-reporting-the-accuracy-and-the-expected-out-of-sample-error" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Running the Model, Reporting the Accuracy and the Expected Out-of-Sample Error</h2>
<pre><code>modfit_rf &lt;- train(classe ~., method="rf", trControl=trainControl(method = "cv", number = 10, savePredictions = TRUE), data=cp_training_data, na.action=na.omit)</code></pre>
<pre><code>## Loading required package: randomForest
## randomForest 4.6-12
## Type rfNews() to see new features/changes/bug fixes.</code></pre>
<pre><code>print(modfit_rf)</code></pre>
<pre><code>## Random Forest 
## 
## 19622 samples
##    55 predictor
##     5 classes: 'A', 'B', 'C', 'D', 'E' 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 17660, 17659, 17660, 17661, 17660, 17660, ... 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa      Accuracy SD  Kappa SD   
##    2    0.9964325  0.9954873  0.001765581  0.002233583
##   30    0.9984710  0.9980661  0.001126849  0.001425167
##   59    0.9964836  0.9955519  0.001470154  0.001859855
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was mtry = 30.</code></pre>
<pre><code>print(modfit_rf$finalModel)</code></pre>
<pre><code>## 
## Call:
##  randomForest(x = x, y = y, mtry = param$mtry) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 30
## 
##         OOB estimate of  error rate: 0.13%
## Confusion matrix:
##      A    B    C    D    E  class.error
## A 5578    1    0    0    1 0.0003584229
## B    6 3789    1    1    0 0.0021069265
## C    0    5 3417    0    0 0.0014611338
## D    0    0    7 3208    1 0.0024875622
## E    0    0    0    3 3604 0.0008317161</code></pre>
<p>The output suggests that the model is very accurate. It has selected a model that uses 30 random predictors at each split (when the variables are bootstrapped). The overall accuracy is 0.9985, which can be confirmed by the confusion matrix and the OOB estimate of error rate.</p>
<p>Regarding the expected out-of-sample error, the confusion matrix reports the OOB esimtate of the error rate to be 0.15%. Since the random forest method calculates each tree by bootstrap where a portion of the sample is left out, I interpreted the OOB estimate of error rate as the expected out-of-sample error.</p>
<p>Finally, the model is used to predict the outcomes for the test sample.</p>
<pre><code>quiz_responses &lt;- predict(modfit_rf, cp_testing_data)</code></pre>
</div>

<p></p>
</div>

<p></p>
</div>







<p>
</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Course Project January 2016 maintained by <a href="https://github.com/hedamar">hedamar</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
